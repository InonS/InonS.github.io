<!doctype html>
<html lang="en">

<head>
    <meta charset="utf-8" />
    <title>Let The Computer Have A Go: Applied Machine Learning (part 1)</title>
    <meta name="author" content="Inon Sharony" />
    <meta name="description" content="Practical application of data science and machine learning, beyond basic theory. Part 1." />
    <meta name="keywords" content="Inon,Sharony,Machine Learning,Data Science,applied,application,presentation,tutorial,HTML5,CSS3" />
    <link href="stylesheets/impress.css" rel="stylesheet" />
    <!-- Open Graph meta-data -->
    <meta property="og:title" content="Let The Computer Have A Go: Applied Machine Learning (part 1)" />
    <meta property="og:type" content="article" />
    <meta property="article:author" content="Inon Sharony" />
    <meta property="article:section" content="Technology" />
    <meta property="og:image" content="images/whiteboard-automated-stacking.png" />
    <meta property="og:url" content="https://inons.github.io/AppliedMachineLearning.html" />
    <meta property="og:description" content="Practical application of data science and machine learning, beyond basic theory. Part 1." />
    <meta property="og:locale" content="en_US" />
</head>

<body background="images/watermark.png">
    <div id="impress">
        <div id="cover" class="step slide" data-x=-2000>
            <a href="https://inons.github.io/AppliedMachineLearning.html"><img style="position: absolute; top: 0; right: 0; border: 0;" src="https://camo.githubusercontent.com/a6677b08c955af8400f44c6298f40e7d19cc5b2d/68747470733a2f2f73332e616d617a6f6e6177732e636f6d2f6769746875622f726962626f6e732f666f726b6d655f72696768745f677261795f3664366436642e706e67" alt="Please cite" data-canonical-src="https://s3.amazonaws.com/github/ribbons/forkme_right_gray_6d6d6d.png "></a>
            <p style="text-align: center ">After action review
                <br><span style="font-size: 60px "><br>Applied Machine Learning</span></p>
            <p style="text-align: center; vertical-align: middle "><a href="https://InonS.GitHub.IO ">Inon Sharony</a>
                <br>
                <time>June 2016</time>
            </p>
            <img src="images/aar_173airborne_bct.jpg" alt="https://www.flickr.com/photos/usarmyeurope_images/6232603158" />
        </div>
        <div id="intro_start" class="step slide" data-x=0>
            <p>How do I approach a data science task? Where do I start?</p>
        </div>
        <div id="intro_planning" class="step slide">
            <p>How do I approach a data science task? Where do I start?</p>
            <p>What is needed of me? How do I measure success? What do I need?</p>
            <p>How do I structure my workplan?</p>
        </div>
        <div id="intro_wrangling" class="step slide">
            <p>How do I approach a data science task? Where do I start?</p>
            <p>What is needed of me? How do I measure success? What do I need?</p>
            <p>How do I structure my workplan?</p>
            <p>How do I structure my dataflow? What data-record transformations do I use?</p>
            <p>What data-feature transformations do I use?</p>
            <p>How do I choose my learning model and optimization algorithm?</p>
        </div>
        <div id="intro_engineering" class="step slide">
            <p>How do I approach a data science task? Where do I start?</p>
            <p>What is needed of me? How do I measure success? What do I need?</p>
            <p>How do I structure my workplan?</p>
            <p>How do I structure my dataflow? What data-record transformations do I use?</p>
            <p>What data-feature transformations do I use?</p>
            <p>How do I choose my learning model and optimization algorithm?</p>
            <p>How do I achieve and maintain agility and scalability?</p>
            <p>How do I secure user acceptance?</p>
        </div>
        <div id="applied_data_science" class="step class" data-z=3000>
            <object data="images/Applied_Data_Science_Presented_by_Yhat.pdf" width="640" height="480 ">Applied Data Science (Y-hat)</object>
        </div>
        <div id="agenda" class="step slide" data-x=2000>
            <h2>Agenda</h2>
            <ul>
                <li>Workflow:</li>
                <ol>
                    <li>POC (domain, data, algo, examples)</li>
                    <li>Escalation (algo, engineering) </li>
                </ol>
                <li>Data Wrangling:</li>
                <ol>
                    <li> Objectives</li>
                    <li> Procedures</li>
                    <li> Example</li>
                </ol>
                <li>Feature Engineering:</li>
                <ol>
                    <li> Manual / Learned</li>
                    <li> Structured / Unstructured</li>
                </ol>
                <li>Diagnostics &amp; Debugging</li>
                <li>Communicating Results</li>
                <li>Next time (in part 2): How to get people to let the computer have a go at some standing problem?</li>
            </ul>
        </div>
        <div id="workflow" class="step slide" data-x=4000>
            <h2 id="Workflowforaparticularepicandfeature" align="center" style="line-height: 400px;">Workflow</h2>
        </div>
        <div id="sprint" class="step slide" data-x=6000>
            <h3 id="Sprint">Sprint</h3>
            <table cellpadding="18px ">
                <tbody style="font-size: 18px; ">
                    <tr>
                        <th colspan="1 ">Week</th>
                        <th>Sun</th>
                        <th>Mon</th>
                        <th>Tue</th>
                        <th>Wed</th>
                        <th>Thu</th>
                    </tr>
                    <tr>
                        <th colspan="1 ">1</th>
                        <td>Release version</td>
                        <td>Release hotfix</td>
                        <td>Kick-off (requirements &amp; specs)</td>
                        <td>Research</td>
                        <td><span>Research</span></td>
                    </tr>
                    <tr>
                        <th colspan="1 ">2</th>
                        <td>Development</td>
                        <td><span>Development</span></td>
                        <td><span>Development</span></td>
                        <td><span>Development</span></td>
                        <td><span>Development</span></td>
                    </tr>
                    <tr>
                        <th colspan="1 ">3</th>
                        <td>Test (QA)</td>
                        <td><span><span>Test (QA)</span></span>
                        </td>
                        <td><span>Alpha testing</span></td>
                        <td><span>Test (STG)</span></td>
                        <td><span>Test (STG)</span></td>
                    </tr>
                </tbody>
            </table>
        </div>
        <div id="poc" class="step slide" data-x=8000>
            <h2 id="ProofOfConcept" align="center" style="text-align: center; vertical-align: middle">Proof Of Concept</h2>
            <img src="images/MVP-2.0.jpg" alt="https://www.anintegratedworld.com/minimum-viable-product-in-reality" height="70%" />
            <p><a href="https://en.wikipedia.org/wiki/Data_mining#Process">KDD process</a>:</p>
        </div>
        <div id="business_domain" class="step slide" data-x=8000 data-y=1000>
            <h3>Business domain</h3>
            <ol>
                <li>Domain model</li>
                <li>Ideation/Hypothesis: Value proposition
                    <br>See
                    <a href="https://youappi.atlassian.net/wiki/display/~Inon/Data+Driven+Value#DataDrivenValue-CounterFactualEvaluation ">Counter-Factual Evaluation</a>
                </li>
                <li>Set in place a (production) feedback mechanism</li>
                <li>Timeliness</li>
                <ul>
                    <li><b>Adaptivity</b> (how fast is <em>the world</em> changing?
                        <br>→ <u>learning rate</u> &amp; <u>validation technique</u>): Event (Reinforcement Learning) vs. batch vs. learn once</li>
                    <li><b>Reactivity</b> (how fast does <em>the response</em> have to be?
                        <br>→ <u>prediction latency</u>): In-app event, e-mailed report,...</li>
                </ul>
                <li>Quantitative specifications</li>
                <ol>
                    <li>Minimally Viable Product (MVP) requirements → KPIs</li>
                    <li>scoring &amp; test method: <a href="https://en.wikipedia.org/wiki/Confusion_matrix ">overall performance</a>, particular mission-critical properties</li>
                </ol>
            </ol>
        </div>
        <div id="data_domain" class="step slide" data-x=8000 data-y=2000>
            <h3><a href="#data_wrangling ">Data domain</a></h3>
            <ol>
                <li>Identification of (possibly) relevant data sources</li>
                <li>Data munging (create data pool by fusion of raw data-sources, e.g. aggregation)</li>
                <li><a href="http://www.itl.nist.gov/div898/handbook/ ">Data model</a></li>
                <li>Data visualization and exploration</li>
                <li>Data cleansing/validation</li>
                <li>Data transformation (e.g. normalization)</li>
            </ol>
        </div>
        <div id="algo_domain" class="step slide" data-x=8000 data-y=3000>
            <h3><a href="http://www.scholarpedia.org/article/Encyclopedia:Computational_intelligence ">Algorithm domain</a></h3>
            <ol>
                <li><a href="#feature_engineering ">Feature* engineering</a></li>
                <li>Auxiliary models (e.g. effect of time elapsed from feature sampling until target sampling, or prediction).</li>
                <li>Choice of learning model and algorithm: </li>
            </ol>
            <p>* 'Feature' in the data science sense, not the software development sense.</p>
        </div>
        <div id="model" class="step slide" data-x=10000 data-y=3000>
            <h4>Model</h4>
            <ol>
                <li>Supervised vs. unsupervised (i.e. quantity and quality of labeled data)</li>
                <li>Univariate vs. multivariate (goal or cost is function of one / many response variables)</li>
                <li>Regression vs. Binary Classification vs. Multi-label Classification vs. Clustering (identify supervised learning task by label, then provide appropriate scoring metrics. e.g. categorical cross-entropy or multi-class log loss for multi-lable classification)</li>
                <li>Parametric vs. non-parametric</li>
                <li>Discriminative (predictive) vs. Generative (causal)</li>
                <li>Accommodate or ignore feature interactions</li>
            </ol>
        </div>
        <div id="algo" class="step slide" data-x=12000 data-y=3000>
            <h4>Optimization algorithm</h4>
            <ol>
                <li>Synchronous vs. asynchronous learning</li>
                <ol>
                    <li><u>Synchronous (On-line)</u>: (stochastic?) iterative solution</li>
                    <ol>
                        <li>Real-time (RT): per-event</li>
                        <li>Near-real-time (a.k.a. "near-time"): mini-batch</li>
                    </ol>
                    <li><u>Asynchronous (Off-line)</u>: batch solution</li>
                </ol>
                <li>Non-parallel vs. Parallel/Distributed (find some separability)
                    <ol>
                        <li><a style="line-height: 1.42857;" href="https://en.wikipedia.org/wiki/Stochastic_approximation ">Stochastic Approximation</a></li>
                        <li><a href="https://en.wikipedia.org/wiki/Category:Probabilistic_data_structures">Probabilistic data structures</a>
                            <br>(c.f. Probabilistic Programming)
                            <li><a href="https://en.wikipedia.org/wiki/Metaheuristic#Parallel_metaheuristics ">meta-heuristics</a></li>
                            <li>Split the cost function, and then optimize (e.g. <a style="line-height: 1.42857;" href="https://en.wikipedia.org/wiki/Augmented_Lagrangian_method#Alternating_direction_method_of_multipliers ">ADMM</a>)</li>
                            <li>GPGPU</li>
                    </ol>
                    </li>
            </ol>
        </div>
        <div id="duality" class="step slide" data-x=12000 data-y=3000 data-z=-2000 data-rotate-y=180 data-scale=2>
            <h4>Duality</h4> Consider solving the <a href="https://en.wikipedia.org/wiki/Duality_(optimization) ">dual problem</a>
            <ol>
                <li>Apply Fourier / Laplace transform for non-stationary joint distributions</li>
                <li>Dual SVM problem</li>
                <li>Matrix Factorization using ALS (particularly where the inverse problem is also of interest, such as in Recommender Systems)</li>
                <li>Projection to Latent Structures (PLS)</li>
            </ol>
        </div>
        <div id="regularization" class="step slide" data-x=14000 data-y=3000>
            <h3>Regularization</h3>
            <ul>
                <li><em>L-1 (LASSO)</em>: Induce feature sparsity (L-0 will induce entry-wise sparsity, but is not convex)</li>
                <li><em>L-2 (Tikhonov regularization a.k.a. ridge regression)</em>: Induce smoothness, reduce multicollinearity </li>
                <li>Some of each (Elastic net)</li>
            </ul>
            The regularization term causes model parameters to shrink, in order to avoid the additional cost incurred. For small parameters, lower regularization order (L-1) will incur a higher cost than a higher order (L-2), making the effects of Regularization more dramatic: From inducing smoothness by decreasing parameter magnitude, to inducing sparsity by taking all but a few parameters to zero. See, for instance, chapter 6 of "An Introduction to Statistical Learning ".
        </div>
        <div id="model_vs_algo_complexity" class="step slide" data-x=16000 data-y=3000>
            <h4>Model complexity vs. feature complexity</h4>
            <ol>
                <li>Long learn time vs. long predict time</li>
                <li>Predictive power is sealed at learn-time vs. predict-time</li>
            </ol>
        </div>
        <div id="algo_examples" class="step slide" data-x=8000 data-y=4000>
            <h3>Learning Algorithm Example</h3>
            <p>e.g. Supervised, parametric, generative, non-interacting, lightweight model, using an iterative algorithm:</p>
            <p><a href="https://en.wikipedia.org/wiki/Generalized_linear_model#Link_function ">GLMs</a> using Stochastic Gradient Descent.</p>
            <br>
            <p>e.g. Supervised, non-parametric, discriminative, interacting, heavyweight model, using a batch algorithm:</p>
            <p><a href="http://www.nature.com/nature/journal/v529/n7587/full/nature16961.html">Deep Neural Network using Monte Carlo tree search</a>.</p>
        </div>
        <div id="escalation" class="step slide" data-x=10000>
            <h2 id="Escalation" align="center" style="line-height: 400px;">Escalation</h2>
        </div>
        <div id="escalation_algorithm" class="step slide" data-x=12000>
            <h3><a href="http://www.scholarpedia.org/article/Encyclopedia:Computational_intelligence ">Algorithm domain</a></h3>
            <img src="images/whiteboard-automated-stacking.png" alt="http://mlwave.com/kaggle-ensembling-guide" />
        </div>
        <div id="metalearning" class="step slide" data-x=12000 data-y=1000>
            <h3><a href="http://www.scholarpedia.org/article/Metalearning ">Meta-learning</a></h3>
            <ol>
                <li><a href="http://www.scholarpedia.org/article/Ensemble_learning ">Ensemble learning</a>: 1 + 1 = 3
                    <br/>
                    <ol>
                        <li>Re-sampling</li>
                        <ol>
                            <li>Deterministic (jackknifing)</li>
                            <li>Stochastic (bagging)</li>
                        </ol>
                        <li><a href="http://mlwave.com/kaggle-ensembling-guide/">Stacked generalization / blending</a></li>
                        <li>Boosting</li>
                        <ul>
                            <li>AdaBoost</li>
                            <li>XGBoost</li>
                            <li>...</li>
                        </ul>
                    </ol>
                </li>
                <li>Self-modification:
                    <ol>
                        <li>Epochs</li>
                    </ol>
                </li>
            </ol>
        </div>
        <div id="model_validation" class="step slide" data-x=12000 data-y=2000>
            <h3>Model validation &amp; selection</h3>
            <ol>
                <li>Cross-validation</li>
                <li>Information Criteria</li>
                <li>Confusion Matrix</li>
                <li>AUC</li>
                <li>A/B user testing: &alpha;, &beta;, production</li>
            </ol>
            <h3>Learning Problem => Validation Method</h3>
            <ol>
                <li>Batch Learning: The learning process has no effect on the subject learned => can validated a particular model.</li>
                <li>On-line Reinforcement Learning: Every time we take an action, the environment may react => only A/B testing.</li>
                <quote>"You could not step twice into the same river."</quote>
                <br>-- Heraclitus
            </ol>
        </div>
        <div id="software" class="step slide" data-x=14000>
            <h2>Software development domain</h2>
            <img src="images/BigPicMetadataMgmt.jpg" alt="https://www.youtube.com/watch?v=Zg9BNGV_DAg" />
        </div>
        <div id="integration" class="step slide" data-x=14000 data-y=1000>
            <h3 style="line-height: 0px"> Product integration</h3>
            <ol>
                <li><b><u>Interface</u></b>: In-database, API, REST, dashboard, ...</li>
                <li><b><u>Data pipeline DAG</u></b>
                    <ol>
                        <li style="line-height: 20px"><b>Edges</b>:
                            <ol>
                                <li><u>Interface</u>: Monads (Single Abstract Method type, e.g. Java @FunctionalInterface)
                                </li>
                                <li><u>Implementation</u>: Functors (function reference plus state, e.g. Java method reference)</li>
                            </ol>
                        </li>
                        <li style="line-height: 20px"><b>Vertices</b>:
                            <ol>
                                <li><u>Spouts</u>: Data sources</li>
                                <li><u>Bolts</u>: Data pools along the pipeline (for resilience, auditing, debugging, etc.)</li>
                            </ol>
                        </li>
                    </ol>
                </li>
                <li><b><u>Scalability</u></b>: Parallelization (e.g. submit micro-batches for prediction, rather than single events), etc.</li>
                <li><b><u>Architecture</u></b>: 3-tier warehouse, Lambda (<a href="https://github.com/killrweather/killrweather">SMACK stack</a>)...</li>
            </ol>
        </div>
        <div id="devops" class="step slide" data-x=14000 data-y=2000 style="line-height: 48px">
            <ul>
                <li><b>Test plan</b></li>
                <li><b>Documentation</b></li>
                <li><b>Configuration management</b>: input parameters, including hyper-parameters
                    <ol>
                        <li>Model ID</li>
                        <li>Model description</li>
                        <li>Model parameters</li>
                        <li>Datetime in-force</li>
                    </ol>
                </li>
                <li><b>Continuous QA</b>: Monitor for performance degradation</li>
                <li><b>Persist historical results</b> (and parameters used to get them, if practical. If not, store the historic models as serialized objects).</li>
            </ul>
        </div>
        <div id="auditing" class="step slide" data-x=16000 data-y=2000>
            <h3>Auditing</h3>
            <ol>
                <li><b>Logs</b></li>
                <li><b>Debug plots</b></li>
                <li><b>DB</b></li>
                <ol>
                    <li>Timestamp</li>
                    <li>Model ID</li>
                    <li>Source code version</li>
                    <li>Input</li>
                    <li>Output</li>
                    <li>Performance metrics</li>
                </ol>
            </ol>
        </div>
        <div id="data_wrangling" class="step slide" data-x=16000>
            <h2 id="DataWrangling" align="center" style="line-height: 400px;">Data Wrangling</h2>
        </div>
        <div id="objectives" class="step slide" data-x=18000>
            <h3 style="text-align: justify;" id="Objectives">Objectives</h3>
            <ul style="margin-left: 2.0em; ">
                <li>No <em>missing</em> values (null, undefined, N/A, ...)</li>
                <li>No <em>invalid</em> values (NaN, inf, ' ', ...)</li>
                <li>No <em>duplicate</em> samples</li>
                <li><em>Enumerable</em> values only (enum, int, or float / double; e.g. no str / object)</li>
                <li><em>Normalized</em> values (each enumerable feature should have values symmetric about the origin, i.e. with zero mean, and unit standard deviation)</li>
                <li><em>Feature engineering</em> (domain logic + intuition =&gt; hypotheses. Since some compound features will derive the greatest contribution, this will usually be followed with some dimensionality reduction)</li>
            </ul>
            <span style="color: red ">Caveat!</span> <b>Rational design</b>: Every data processing decision will probably affect the model's predictive performance.
        </div>
        <div id="eda" class="step slide" data-x=20000>
            <h3 style="text-align: justify;" id="eda">Exploratory Data Analysis</h3>
            <ol>
                <li>Overview data schema</li>
                <ol>
                    <li>R <a href="https://stat.ethz.ch/R-manual/R-devel/library/base/html/summary.html ">summary {base}</a></li>
                    <li><a href="http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.describe.html ">pandas.DataFrame.describe</a></li>
                    <li><a href="https://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.sql.DataFrame ">spark.DataFrame.describe</a></li>
                </ol>
                <li><a href="http://www.itl.nist.gov/div898/handbook/eda/section3/eda34.htm ">Data visualization</a></li>
                <ol>
                    <li>Use a notebook (Jupyter, Zeppelin, etc.)</li>
                    <li>Boxplot (univariate or bivariate, i.e. Bagplot)</li>
                    <li>Test assumptions of normality and homoscedasticity using <a href="http://www.itl.nist.gov/div898/handbook/eda/section3/4plot.htm ">4-Plot</a></li>
                </ol>
            </ol>
        </div>
        <div id="dimensionality" class="step slide" data-x=20000 data-y=1000>
            <h3>Dimensionality Reduction</h3>
            <ol>
                <li>Record linkage</li>
                <li>Database normalization</li>
                <li><u>Matrices</u></li>
                <ol>
                    <li>Reshape matrices to standard shape</li>
                    <li>Sparse matrices</li>
                </ol>
                <li><u>Interactions</u></li>
                <ol>
                    <li>Scatter-plot matrix</li>
                    <li>MANOVA</li>
                    <li> cross-correlations (also auto-correlations in the case of time-series data)</li>
                </ol>
            </ol>
            </li>
            </ol>
        </div>
        <div id="data_cleansing" class="step slide" data-x=20000 data-y=2000>
            <h3>Data cleansing</h3> Cleanse features with missing, invalid, innumerable, or un-normalized values:
            <ol>
                <li><u>Missing</u>: Drop (<em>filter</em>) entire <i>record</i> or <em>imputate</em> (fill) <i>value</i>?
                    <ol>
                        <li>If filling in, what with? zero-order = most probable (mode), more complex logic...</li>
                        <li><u>Selection bias</u>: Find ways to compensate for data which was not measured, in order to take the base rate into account.</li>
                        <li>Consider using a CART model.</li>
                    </ol>
                </li>
                <li><u>Invalid</u>: Manipulate (<em>transform</em>) or <em>replace</em>?</li>
            </ol>
            Add new data columns for the cleansed and compounded data, rather than overwriting the original columns.
        </div>
        <div id="data_cleansing2" class="step slide" data-x=20000 data-y=3000>
            <h3>More data-record transformations</h3>
            <li><u>Duplicate</u>: Merge duplicate (or near-duplicate) samples, and compensate by introducing a double weight for the effect of the merged sample on the model.</li>
            <li>Is <em>enumeration </em>viable?
                <br/>
                <ol>
                    <li><em>Hashing trick</em> (i.e. feature vectorization)</li>
                    <li> Text-feature extraction: OneHotEncoder, td-idf (e.g. in both scikit-learn and spark), StringIndexer, Tokenizer, word2vec (e.g. in spark.ml), etc.</li>
                </ol>
            </li>
        </div>
        <div id="outliers" class="step slide" data-x=20000 data-y=4000>
            <h3>Tolerance of Outliers</h3>
            <ol>
                <li><em>Censoring</em> (filtering) or <em>imputation</em> (value truncation, e.g. winsorization) of outliers</li>
                <li>Long-tail effect on location statistic: average vs. median.</li>
                <li>Including a variability statistic (e.g. range, variance)</li>
                <li>Confidence intervals using bootstrapping</li>
                <li>Binning of variables whose dynamic-range is large. Visualize using histograms to select the most appropriate bin intervals.</li>
                <li>Robust Statistical Methods (e.g. Robust Linear Regression, from the Theil-Sen Estimator to Redescending M-estimators)</li>
            </ol>
        </div>
        <div id="transformations" class="step slide" data-x=20000 data-y=5000>
            <h3>Value Normalization by Mathematical Transformations</h3> To attain zero mean and uniform (&#8733; unit) variance:
            <ol>
                <li>Logarithmic transformations (log, semi-log, log-log).</li>
                <li>Box–Cox (Power) Transformation</li>
            </ol>
        </div>
        <div id="db_normalization" class="step slide" data-x=20000 data-y=6000>
            <h3>DB Normalization</h3>
            <ol>
                <li>Decomposition of composite data into multiple, primitive typed fields</li>
                <li>Aggregation of identical observations using 'sum'/'count' fields.</li>
                <li><u>Propositionalization</u>: RDB Feature Synthesis (e.g. Deep Feature Synthesis)</li>
            </ol>
        </div>
        <div id="feature_selection" class="step slide" data-x=20000 data-y=7000>
            <h3>Feature selection</h3>
            <ol>
                <li>Consider <em>removing noisy features</em> (e.g. mostly missing or unreliable for any other reason), to attempt more concise models first.</li>
                <li><em>Correlation does not imply causation</em></li>
                <ol>
                    <li><u>Problem</u>: Some feature A, highly correlates with the target variable, but offers little predictive power.</li>
                    <li><u>Solution</u>:
                        <ol>
                            <li>Introduce more feature/s which have low correlation with A, or drop A altogether.</li>
                            <li>Consider keeping features even if they have low correlation with the target variable, directly.</li>
                        </ol>
                    </li>
                </ol>
                <li>Add <em>compound features</em>, as needed. e.g. the <em>kernel trick</em></li>
            </ol>
        </div>
        <div id="cross_validation" class="step slide" data-x=20000 data-y=8000>
            <h3>Cross-Validation</h3>
            <ul>
                <li>Data contamination / leakage: Take care that data present in the test set is not reflected directly or indirectly in the training set.</li>
                <li>For uneven data sets, employ stratified sampling (particularly for classification).</li>
            </ul>
            <h3>Randomization</h3>
            <ul>
                <li><u>Rare event sampling</u>: Sample a comparable number of non-interesting events as the interesting ones, and give the former a proportional weight when fitting. (Proportional to their original fraction in the sample set) </li>
                <li><u>Data splitting</u>: The test set should be 20%-30% of the samples, and the rest can be trained on. See also re-sampling.</li>
            </ul>
        </div>
        <div id="data_pipeline" class="step slide" data-x=20000 data-y=9000>
            <h3>Data Pipeline</h3>
            <ul>
                <li>The various cleansing and compounding stages can be programmed to execute sequentially, as part of an, e.g. spark.ml.Pipeline, and followed by 'train/fit' and 'test/score' phases.</li>
                <li>Feature <a href="http://scikit-learn.org/stable/modules/classes.html#module-sklearn.feature_extraction">extraction</a>, <a href="http://scikit-learn.org/stable/modules/classes.html#module-sklearn.preprocessing">preprocessing (including normalization)</a>, and <a href="http://scikit-learn.org/stable/modules/classes.html#module-sklearn.feature_selection">selection</a> (including dimensionality reduction techniques such as <a href="http://scikit-learn.org/stable/modules/classes.html#module-sklearn.decomposition">matrix factorization/decomposition</a>) transformations in scikit-learn or in <a href="http://spark.apache.org/docs/latest/ml-features.html">spark.ml</a></li>
                <li>Concatenate features from different transformer stages using feature stacking (e.g. in <a href="http://docs.scipy.org/doc/numpy/reference/generated/numpy.hstack.html">numpy</a> or <a href="http://scikit-learn.org/stable/modules/generated/sklearn.pipeline.FeatureUnion.html#sklearn.pipeline.FeatureUnion">scikit-learn</a>)</li>
                <li>Rather than using one monolithic model, it can be more robust to aggregate predictions from multiple light-weight models, each using only a few features (for ensemble methods also small number of estimators).</li>
            </ul>
        </div>
        <div id="process_engineering" class="step slide" data-x=20000 data-y=10000>
            <h3>Process engineering</h3>
            <ol>
                <li><a href="http://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html#sklearn.pipeline.Pipeline">Scikit-learn Pipeline</a> or <a href="http://spark.apache.org/docs/latest/ml-guide.html#example-pipeline">spark.ml.Pipeline</a> for conveniently transferring each extractor, transformer, and evaluator from the training phase for use in the testing/validation and prediction phases.</li>
                <li>Model selection and ensemble learning</li>
                <li>Use <a href="http://scikit-learn.org/stable/modules/classes.html#module-sklearn.grid_search">grid_search</a> to scan hyper-parameters within a reasonable range (probably never exceed two orders of magnitude from standard parameter value).</li>
                <li>Multi-level models: See <a href="#/metalearning">ensemble/meta- learning</a></li>
            </ol>
        </div>
        <div id="extract_chrono" class="step slide" data-x=22000>
            <h3 id="ExtractDateTime " align="center" style="line-height: 400px;">Example: Extract Date &amp; Time by chrono fields</h3>
        </div>
        <div id="normalized_fields" class="step slide" data-x=22000 data-y=1000>
            <h4>Normalized fields:</h4>
            <ol>
                <li>Century (zero-based): e.g. 20 for 20XX</li>
                <li>Year in century: 00-99</li>
                <li>Month of year: 1-12</li>
                <li>Day of month: 1-31</li>
                <li>Hour of day: 00-23</li>
                <li>Minute of hour: 00-59</li>
                <li>Second of minute: 00-59</li>
                <li>Milli of second: 000-999</li>
            </ol>
        </div>
        <div id="derived_fields" class="step slide" data-x=22000 data-y=2000>
            <h4>Derived informative fields:</h4>
            <ol>
                <li>Season of year: S/F/W/S</li>
                <li>Week of year: 1-52</li>
                <li>Week of month: 1-5</li>
                <li>Day of year: 1-366</li>
                <li>Day of week: 1-7</li>
                <li>Is weekend? True/False</li>
                <li>Is daytime? True/False</li>
            </ol>
            <h4>Seasonality</h4> Expect about 15% of metrics to have seasonality. ~70% will have daily period, and another ~25% will have weekly period, leaving no more than 5% for any other periodicity.
        </div>
        <div id="feature_engineering" class="step slide" data-x=24000>
            <h2 id="FeatureEngineeringFeatureengineeringapproaches " align="center " style="line-height: 400px;">Feature engineering approaches</h2>
        </div>
        <div id="manual-features" class="step slide" data-x=24000 data-y=1000>
            <h3>Manual Feature Engineering</h3>
            <ol>
                <li>Extraction → </li>
                <li>Selection → </li>
                <li>Reduction</li>
            </ol>
            </li>
        </div>
        <div id="learned-features" class="step slide" data-x=24000 data-y=2000>
            <h3>Learned Feature Engineering</h3>
            <ol>
                <li><b>Structured data</b>:
                    <ol>
                        <li><u>Neglecting interactions</u>: Factorization of the design matrix</li>
                        <li><u>Include interactions</u></li>
                        <ol>
                            <li>Regularization</li>
                            <li>Pruned CARTs</li>
                        </ol>
                        <li>Cluster Analysis</li>
                        <ol>
                            <li>Input <em>k</em>: centroid (also spectral) or distribution based</li>
                            <li>Output <em>k</em>: hierarchical or density based</li>
                        </ol>
                    </ol>
                </li>
                <li><b>Unstructured data</b>:
                    <ol>
                        <li>Artificial Neural Networks</li>
                    </ol>
                </li>
            </ol>
        </div>
        <div id="unstructured_data" class="step slide" data-x=24000 data-y=3000>
            <p>Examples of unstructured data most amenable to ANNs:</p>
            <ol>
                <li>NLP</li>
                <li>media
                    <ol>
                        <li>audio</li>
                        <li>images</li>
                        <li>video</li>
                    </ol>
                </li>
            </ol>
            <p>Convolutional Net (Deep Learning) image processing hueristic:</p>
            <ol>
                <li><u>First layer</u>: Pixel-intensity features</li>
                <li><u>Second layer</u>: Multiple-pixel features (segmentation, etc.)</li>
                <li><u>Subsequent layers</u>: More complex features/tasks (object recognition, etc.)</li>
            </ol>
        </div>
        <div id="diagnostics_and_debugging" class="step slide" data-x=26000>
            <h2 id="mldebugDiagnostics&amp;debugging">Diagnostics &amp; debugging</h2>
            <ol>
                <li>Anamnesis</li>
                <ol>
                    <li>Last change in parameter values</li>
                    <li>Value of regularization function</li>
                    <li>Value of cost function</li>
                    <li>Value of Kullback-Leibler divergence</li>
                    <li>Value of scoring function on training set</li>
                    <li>Value of scoring function on test set</li>
                </ol>
                <li>Diagnosis</li>
                <ol>
                    <li>Optimization algorithm (cost has not converged)</li>
                    <li>High bias (training error &gt;&gt; acceptable test error)</li>
                    <li>High variance (training error &lt;&lt; test error)</li>
                    <li>Optimization objective is not representative
                        <br>(goal &gt;&gt; score; goal function is negative cost function)</li>
                </ol>
            </ol>
        </div>
        <div id="resolution" class="step slide" data-x=26000 data-y=1000>
            <h4>Prescription &#8478;</h4>
            <ol>
                <li>Optimization algorithm does not converge</li>
                <ul>
                    <li>Run more iterations</li>
                    <li>Change initial parameter values</li>
                    <li>Switch to adaptive step size / learning rate</li>
                    <li>Switch optimization algorithm (check <a href="http://www.itl.nist.gov/div898/handbook/eda/section3/6plot.htm ">6-Plot</a>)</li>
                </ul>
                <li>High bias</li>
                <ul>
                    <li>Include more features (which were initially excluded)</li>
                    <li>Get/generate new features</li>
                </ul>
                <li>High variance</li>
                <ul>
                    <li>Get more training samples</li>
                    <li>Exclude more features</li>
                </ul>
                <li>Optimization objective is not representative</li>
                <ul>
                    <li>Change meta-parameters (regularization / margin)</li>
                    <li>Switch ML model</li>
                </ul>
            </ol>
        </div>
        <div id="error_analysis" class="step slide" data-x=26000 data-y=2000>
            <ul>
                <li><u>Error Analysis</u></li>
                How much <em>worse</em> is the current error, relative to <em>perfect performance</em>, due to each system component (data transformation, feature sub-set)? Start backwards from output, and plug in the <em>ground-truth</em> into increasingly earlier components. Check how much the error in output changes with the addition of each component.
                <li><u>Ablative Analysis</u></li>
                How much <em>better</em> is the current error, due to each system component, relative to the performance expected <em>without it</em>? Define the minimal viable system. Then, starting with the full system, remove one component at a time, check the change in error, and stop when reaching a state where no more components can be removed.
            </ul>
        </div>
        <div id="communicating_results" class="step slide" data-x=28000>
            <h2 id="Communicatingresults " align="center " style="line-height: 400px;">Communicating results</h2>
        </div>
        <div id="presentation_animations" class="step slide" data-x=28000 data-y=1000>
            <h2 id="PresentationAnimationsPresentationanimations">Presentation animations</h2>
            <ol>
                <li>overview &amp; each top-level step as a separate module</li>
                <li>zoom in on each module, while keeping overall perspective</li>
                <li>non-linear flows: e.g. cycles (feedback loops)</li>
                <li>consider orientation: go from top-down, top-left to bottom-right, left-to-right, outside-in, etc.</li>
                <li>use non-default font, attractive 3D graphics, toned-down colors, and toned-down photos/clipart/icons (only where appropriate beyond doubt)</li>
                <li>hyper-link from each module slide to it's composing modules, and back up to the level above it</li>
                <li>use animated transitions to create a sense of motion (but avoid motion-sickness). For example, <a href="http://strut.io/editor/ ">strut.io</a>.</li>
            </ol>
        </div>
        <div id="impressjs" class="step slide" data-x=28000 data-y=2000>
            <h3>impress.js</h3>
            <ul>
                <li>Use the source, Luke!
                    <ul>
                        <li><a href="view-source:http://impress.github.io/impress.js/ ">impress.js</a></li>
                        <li><a href="https://raw.githubusercontent.com/impress/impress.js/master/css/impress-demo.css ">demo stylesheet (CSS)</a></li>
                    </ul>
                </li>
                <li>Editors
                    <ol>
                        <li>Markdown: <a href="http://slideshow-templates.github.io/slideshow-impress.js/slides.html ">Slideshow (impress.js template)</a></li>
                        <li>reStructuredText: <a href="http://regebro.github.io/hovercraft ">Hovercraft!</a></li>
                        <li>GUI: <a href="http://strut.io/editor ">Strut.io</a></li>
                    </ol>
                </li>
            </ul>
        </div>
        <div id="questions" class="step slide" data-x=30000 align="center " style="line-height: 240px;">
            <big>Contact me if you'd like to know more!</big>
            <br>
            <a href="https://il.linkedin.com/in/inonsharony ">Inon Sharony</a>,
            <time>June 2016</time>
            <br>
            <a href="http://blog.kaggle.com/category/winners-interviews/">Kaggle winners' interviews</a>
        </div>
        <div id="overview" class="step" data-x=15000 data-scale=20>
        </div>
    </div>
    <script src="js/impress.js "></script>
    <script>
    impress().init();
    </script>
</body>

</html>